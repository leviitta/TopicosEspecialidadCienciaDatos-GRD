Predicci√≥n de Grupos Relacionados por el Diagn√≥stico (GRD) mediante Machine Learning

Este proyecto tiene como objetivo desarrollar y evaluar modelos de machine learning para predecir la clasificaci√≥n de un paciente en un Grupo Relacionado por el Diagn√≥stico (GRD). La predicci√≥n se basa en datos cl√≠nicos como la edad, el sexo, los diagn√≥sticos y los procedimientos m√©dicos asociados a su hospitalizaci√≥n.

El GRD es un sistema de clasificaci√≥n de pacientes que agrupa casos cl√≠nicamente similares y que se espera que consuman una cantidad parecida de recursos hospitalarios. Una predicci√≥n precisa del GRD puede ayudar a los centros de salud en la gesti√≥n de recursos, la planificaci√≥n y la optimizaci√≥n de la atenci√≥n al paciente.

üìú Tabla de Contenidos
Metodolog√≠a del Proyecto

  - Librer√≠as y Tecnolog√≠as

  - Estructura del C√≥digo

  - C√≥mo Ejecutar el C√≥digo

  - Resultados

  - Posibles Mejoras

üõ†Ô∏è Metodolog√≠a del Proyecto
El flujo de trabajo de este proyecto se puede dividir en las siguientes etapas clave:

1. Carga y Limpieza de Datos:

    - Se carga el dataset dataset_elpino.csv desde Google Drive.
    - Se crea la variable objetivo Label extrayendo y limpiando la informaci√≥n de la columna original GRD.
    - Se eliminan las categor√≠as (clases de Label) con una frecuencia muy baja (inferior al 0.4%) para reducir el ruido y el desbalance extremo.
    - Se descartan filas y columnas que superan un umbral del 75% de valores nulos para asegurar la calidad de los datos.

2. An√°lisis Exploratorio de Datos (EDA):

    - Se visualiza la distribuci√≥n de la variable objetivo (Label) para entender el desbalance de clases.
    - Se analizan las distribuciones de caracter√≠sticas demogr√°ficas clave como la edad y el sexo de los pacientes.

3. Preprocesamiento e Ingenier√≠a de Caracter√≠sticas:

    - Imputaci√≥n de Nulos: Los valores faltantes en columnas num√©ricas se rellenan con la mediana, y en las categ√≥ricas, con la moda.
    - Extracci√≥n de C√≥digos: Para las columnas de diagn√≥sticos y procedimientos, se extrae √∫nicamente el c√≥digo (ej. C189), descartando la descripci√≥n textual para simplificar el procesamiento.

    - Pipeline de Preprocesamiento: Se utiliza ColumnTransformer de Scikit-learn para aplicar transformaciones espec√≠ficas a cada tipo de columna:

      - Variables Num√©ricas (Edad en a√±os): Imputaci√≥n con la mediana y escalado con StandardScaler.

      - Variables Categ√≥ricas (Sexo (Desc)): Imputaci√≥n con la moda y codificaci√≥n con OneHotEncoder.

      - C√≥digos de Diagn√≥stico y Procedimientos: Se utiliza TargetEncoder, una t√©cnica de codificaci√≥n avanzada ideal para variables categ√≥ricas de alta cardinalidad. Este codificador reemplaza cada c√≥digo por la media de la variable objetivo, capturando as√≠ poder predictivo.

4. Modelado y Optimizaci√≥n:

    - Manejo del Desbalance de Clases: Se integra SMOTETomek en el pipeline. Esta t√©cnica de remuestreo combina el sobremuestreo de las clases minoritarias (SMOTE) con la limpieza de enlaces entre clases (Tomek Links), generando un conjunto de datos de entrenamiento m√°s balanceado.

    - Reducci√≥n de Dimensionalidad: Se aplica PCA (An√°lisis de Componentes Principales) para reducir la dimensionalidad del conjunto de datos tras la codificaci√≥n, conservando un porcentaje de la varianza (95%, 97% o 99%).

    - Comparaci√≥n de Modelos: Se entrenan y comparan dos potentes algoritmos de clasificaci√≥n: RandomForestClassifier y LightGBM.

    - B√∫squeda de Hiperpar√°metros: Se utiliza GridSearchCV con validaci√≥n cruzada estratificada de 5 folds (StratifiedKFold) para encontrar la mejor combinaci√≥n de hiperpar√°metros para cada modelo. La m√©trica de evaluaci√≥n optimizada es el F1-score ponderado, adecuada para problemas multiclase con desbalance.

    - Evaluaci√≥n Final: El mejor modelo encontrado durante la b√∫squeda se eval√∫a sobre un conjunto de prueba (test set) previamente separado para medir su rendimiento en datos no vistos.

üíª Librer√≠as y Tecnolog√≠as
El proyecto se desarrolla en Python 3 y se ejecuta en un entorno de Google Colab. Las principales librer√≠as utilizadas son:

    - An√°lisis y Manipulaci√≥n de Datos: pandas, numpy

    - Visualizaci√≥n: matplotlib, seaborn

    - Machine Learning y Preprocesamiento: scikit-learn

    - Codificaci√≥n Avanzada: category-encoders

    - Manejo de Desbalance: imbalanced-learn

    - Modelos de Clasificaci√≥n: lightgbm

üìÇ Estructura del C√≥digo:

El script Topicos_de_especialidad_Ciencia_de_Datos_GRD.ipynb contiene todo el flujo de trabajo, incluyendo varias funciones personalizadas para facilitar la reproducibilidad:

    - construir_columna_label(): Procesa la columna GRD original para crear la variable objetivo.

    - eliminar_label_por_porcentaje(): Filtra las clases minoritarias del target.

    - eliminar_filas_nulas_x_porcentaje() y eliminar_columnas_nulas_x_porcentaje(): Funciones para la limpieza de datos nulos.

    - imputar_numericas_con_mediana() y imputar_categoricas_con_moda(): Rellenan valores faltantes.

    - Funciones de visualizaci√≥n (plot_*): Generan gr√°ficos para el EDA.

üöÄ C√≥mo Ejecutar el C√≥digo:

Este proyecto est√° dise√±ado para ejecutarse en Google Colab. Para reproducir los resultados, sigue estos pasos:

    - Clona o descarga el repositorio.

    - Sube el notebook a Google Colab.

    - Prepara el dataset:

      - Aseg√∫rate de tener el archivo dataset_elpino.csv.

      - S√∫belo a tu Google Drive.

    - Modifica la siguiente l√≠nea en el c√≥digo para que apunte a la ruta correcta de tu archivo:

      - ruta_data_set_GRD = 'gdrive/My Drive/ruta/a/tu/dataset/dataset_elpino.csv'

    - Instala las dependencias: La primera celda del notebook se encarga de instalar las librer√≠as necesarias:

      - !pip install category_encoders

Ejecuta todas las celdas: Haz clic en Entorno de ejecuci√≥n > Ejecutar todo en Google Colab. El script te pedir√° autorizaci√≥n para montar tu Google Drive.

üìä Resultados:

El script realiza una b√∫squeda exhaustiva de hiperpar√°metros para los modelos RandomForest y LightGBM. La siguiente tabla resume los resultados obtenidos durante la validaci√≥n cruzada:

    - Modelo	Mejor F1-score Ponderado (CV)	Mejores Hiperpar√°metros
      - LightGBM	0.490532	{'model__learning_rate': 0.1, 'model__n_estimators': 200, 'model__num_leaves': 40, 'pca__n_components': 0.99}
      - Random Forest	0.490744	{'model__max_depth': None, 'model__min_samples_leaf': 1, 'model__n_estimators': 200, 'pca__n_components': 0.99}

Exportar a Hojas de c√°lculo
El mejor modelo, LightGBM, fue evaluado en el conjunto de prueba, obteniendo un rendimiento final de:

    - F1-score ponderado en el conjunto de prueba: 0.4714

Este resultado indica que el modelo final es no capaz de predecir correctamente el GRD de un paciente con una alta precisi√≥n y robustez.

üí° Posibles Mejoras:

    - Explorar otros modelos: Probar otros algoritmos como XGBoost, CatBoost o incluso redes neuronales.

    - Ingenier√≠a de Caracter√≠sticas Avanzada: Crear nuevas caracter√≠sticas a partir de las existentes, como el n√∫mero de diagn√≥sticos secundarios o el tipo de procedimiento principal.

    - Optimizaci√≥n de TargetEncoder: Ajustar los par√°metros de suavizado (smoothing) del TargetEncoder para evitar el sobreajuste.

    - An√°lisis de Errores: Investigar en qu√© clases de GRD el modelo comete m√°s errores para entender sus debilidades y proponer mejoras espec√≠ficas.
